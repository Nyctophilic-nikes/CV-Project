{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage.feature import local_binary_pattern\n",
    "import os\n",
    "from FeatureExtractor import *\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Videos = ['Pigs_49651_960_540_500f','Koi_5652_952_540',\\\n",
    "          'Pigeons_8234_1280_720','Pigeons_4927_960_540_600f', \\\n",
    "          'Pigeons_29033_960_540_300f']\n",
    "\n",
    "# The individual clips should be stored in folders with the respective\n",
    "# names. For example, folder 'Koi_5652_952_540_clips' should contain\n",
    "# subfolders 'Catherine', 'Dwayne', 'Florence', etc, with the \n",
    "# individual images. MATLAB code for splitting the video, storing the\n",
    "# frames and creating the folders with the clips is provided in this\n",
    "# repository.\n",
    "\n",
    "cl_names = ['Linear Discriminant Analysis', '3-nn', 'Decision Tree',\n",
    "            'SVM', 'Bagging', 'Random Forest'] # classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------\n",
    "def select_half_video(folder,bb_file,part = 1):\n",
    "    \n",
    "    bb = pd.read_csv(bb_file,header = None)    \n",
    "    bb = bb.to_numpy()\n",
    "   \n",
    "    # Find the number of frames in the video\n",
    "    lasf_file_name = bb[-1,5]\n",
    "    f = np.int(lasf_file_name[5:10]) \n",
    "    half_f = np.floor(f/2).astype(int)\n",
    "    \n",
    "    images, labels = [],[]\n",
    "    for i in range(len(bb)):\n",
    "        z = bb[i,5] # take the file name\n",
    "        nn = np.int(z[5:10]) # convert to numeric\n",
    "        flag = ((part == 1) & (nn <= half_f)) | \\\n",
    "            ((part == 2) & (nn > half_f)) \n",
    "        if flag:\n",
    "            label = bb[i,0]# take the string label\n",
    "            label = label.replace(' ','') # trim the blanks\n",
    "            filename = bb[i,5] \n",
    "            fn = label+'/'+ label + '_frame_' + filename[5:10] + '.jpg'\n",
    "            img = plt.imread(folder+'/'+fn)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                print(folder+'/'+fn)     \n",
    "            \n",
    "    return images, labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_testing_rows(bb_file,part = 1):\n",
    "    \n",
    "    bb = pd.read_csv(bb_file,header = None)    \n",
    "    bb = bb.to_numpy()\n",
    "   \n",
    "    # Find the number of frames in the video\n",
    "    lasf_file_name = bb[-1,5]\n",
    "    f = np.int(lasf_file_name[5:10]) \n",
    "    half_f = np.floor(f/2).astype(int)\n",
    "    \n",
    "    index = []\n",
    "    for i in range(len(bb)):\n",
    "        z = bb[i,5] # take the file name\n",
    "        nn = np.int(z[5:10]) # convert to numeric\n",
    "        flag = ((part == 1) & (nn <= half_f)) | \\\n",
    "            ((part == 2) & (nn > half_f)) \n",
    "        if flag:\n",
    "            index.append(i)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(images, r = 50, verbose = False):\n",
    "    # Extracts basic features.\n",
    "    # All images are first resized to r-by-r pixels.\n",
    "    # Use verbose = True to see a 4x4 grid of images \n",
    "    \n",
    "    if verbose:\n",
    "        plt.figure(figsize = (10,10))\n",
    "        k = 1 # subplot index\n",
    "        khog = 1\n",
    "        grid_size = 4\n",
    "    \n",
    "    for img in images:\n",
    "        if verbose:\n",
    "            if k <= grid_size**2:\n",
    "                plt.subplot(grid_size,grid_size,k)\n",
    "                plt.imshow(img)\n",
    "                plt.axis('Off')\n",
    "                k +=1   \n",
    "        \n",
    "        resized_img = resize(img, (r, r))\n",
    "        \n",
    "        #creating HOG features ----------------------------------------------------\n",
    "        fd = hog(resized_img, orientations=9, pixels_per_cell=(8, 8), \\\n",
    "                    cells_per_block=(1, 1), multichannel=True)\n",
    "\n",
    "        fd = np.reshape(fd,(1,-1))\n",
    "        if 'DataHOG' in locals():\n",
    "            DataHOG = np.append(DataHOG,fd,axis = 0)\n",
    "        else:\n",
    "            DataHOG = fd\n",
    "\n",
    "        radius = 3\n",
    "        n_points = 8 * radius\n",
    "        method = 'default'\n",
    "        \n",
    "        #creating LBP features ----------------------------------------------------\n",
    "        nbins = 50 # this will be my number of features\n",
    "        \n",
    "        lbp_raw = local_binary_pattern(rgb2gray(img), n_points, radius, method)\n",
    "        lbp,_ = np.histogram(lbp_raw,bins = 50)\n",
    "        lbp = lbp/np.sum(lbp)\n",
    "        lbp = np.reshape(lbp,(1,-1))\n",
    "\n",
    "        if 'DataLBP' in locals():\n",
    "            DataLBP = np.append(DataLBP,lbp,axis = 0)\n",
    "        else:\n",
    "            DataLBP = lbp\n",
    "            \n",
    "        #creating Block RGB features -----------------------------------------------       \n",
    "        rgb = fox_get_colour_features(img, fstr = 'RGB', blocks_r = 3, \n",
    "            blocks_c = 3, bins = 20)\n",
    "        rgb = np.reshape(rgb,(1,-1))\n",
    "        if 'DataRGB' in locals():\n",
    "            DataRGB = np.append(DataRGB,rgb,axis = 0)\n",
    "        else:\n",
    "            DataRGB = rgb\n",
    "            \n",
    "        #creating H10 features ---------------------------------------------------\n",
    "        hsv_img = rgb2hsv(img)\n",
    "        hue_img = hsv_img[:, :, 0]\n",
    "        \n",
    "        h10 = fox_get_colour_features(img, fstr = 'H', blocks_r = 1, \n",
    "            blocks_c = 1, bins = 10)\n",
    "        \n",
    "        h10 = np.reshape(h10,(1,-1))\n",
    "        if 'DataH10' in locals():\n",
    "            DataH10 = np.append(DataH10,h10,axis = 0)\n",
    "        else:\n",
    "            DataH10 = h10\n",
    "        \n",
    "    if verbose:\n",
    "        plt.show()\n",
    "   \n",
    "    return DataHOG, DataLBP, DataRGB, DataH10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#####  Pigs_49651_960_540_500f  #####\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m bb_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../BB_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m video \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Read training and testing data (half video; must not be random!)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m imds_1,labels_1 \u001b[38;5;241m=\u001b[39m \u001b[43mselect_half_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbb_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# training\u001b[39;00m\n\u001b[0;32m     28\u001b[0m imds_2,labels_2 \u001b[38;5;241m=\u001b[39m select_half_video(folder,bb_file,part \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# testing\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Repair the data (missing classes in training data)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Find missing classes and remove those from both sets\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m, in \u001b[0;36mselect_half_video\u001b[1;34m(folder, bb_file, part)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Find the number of frames in the video\u001b[39;00m\n\u001b[0;32m      8\u001b[0m lasf_file_name \u001b[38;5;241m=\u001b[39m bb[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m----> 9\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m(lasf_file_name[\u001b[38;5;241m5\u001b[39m:\u001b[38;5;241m10\u001b[39m]) \n\u001b[0;32m     10\u001b[0m half_f \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloor(f\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     12\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m [],[]\n",
      "File \u001b[1;32mc:\\Users\\HP\\scoop\\apps\\python\\current\\Lib\\site-packages\\numpy\\__init__.py:338\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    333\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'int'.\n`np.int` was a deprecated alias for the builtin `int`. To avoid this error in existing code, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "# CALCULATIONS\n",
    "\n",
    "# Calculate and display the training and testing accuracies\n",
    "# of the 6 classifiers and the 4 data representations:\n",
    "# HOG, LBP, RGB, H10. The data representations as well as\n",
    "# the labels for the training and testing data are stored \n",
    "# in csv files. Each file contains the training data\n",
    "# followed by the testing data.\n",
    "\n",
    "Sizes = np.zeros((len(Videos),3)) \n",
    "# info about training and testing data\n",
    "\n",
    "plot_flag = False\n",
    "r = 56\n",
    "\n",
    "for v in range(len(Videos)):\n",
    "    \n",
    "    video = Videos[v]\n",
    "\n",
    "    print('\\n\\n#####  ' + video + '  #####\\n\\n')\n",
    "    \n",
    "    folder = \"../\" + video + \"_clips\"\n",
    "    bb_file = \"../BB_\" + video + \".csv\"\n",
    "\n",
    "    # Read training and testing data (half video; must not be random!)\n",
    "    imds_1,labels_1 = select_half_video(folder,bb_file,part = 1) # training\n",
    "    imds_2,labels_2 = select_half_video(folder,bb_file,part = 2) # testing\n",
    "    \n",
    "    # Repair the data (missing classes in training data)\n",
    "    # Find missing classes and remove those from both sets\n",
    "\n",
    "    ll = list(np.sort(np.unique(labels_1)))\n",
    "    n_classes = len(ll)\n",
    "\n",
    "    X_train_im = []\n",
    "    X_train = []\n",
    "    y_train_num = []\n",
    "    for i in range(len(imds_1)):\n",
    "        y_train_num.append(ll.index(labels_1[i]))\n",
    "        X_train.append(resize(imds_1[i], (r, r)))\n",
    "        X_train_im.append(imds_1[i])   \n",
    "    X_train = np.array(X_train)/255                       \n",
    "\n",
    "    X_test_im = []\n",
    "    X_test = []\n",
    "    y_test_num = [] # numerical testing labels\n",
    "    for i in range(len(imds_2)):\n",
    "        if labels_2[i] in set(ll):\n",
    "            y_test_num.append(ll.index(labels_2[i]))\n",
    "            X_test.append(resize(imds_2[i], (r, r)))\n",
    "            X_test_im.append(imds_2[i])\n",
    "    X_test = np.array(X_test)/255    \n",
    "\n",
    "    print('Training size = ',X_train.shape,' Testing size = ',X_test.shape, '\\n')\n",
    "    \n",
    "    Sizes[v,0] = len(y_train_num)\n",
    "    Sizes[v,1] = len(y_test_num)\n",
    "    Sizes[v,2] = n_classes\n",
    "    \n",
    "    print(Sizes)\n",
    "    \n",
    "    data_train = extract_features(X_train, r = r, verbose = False)\n",
    "    data_test = extract_features(X_test, r = r, verbose = False)\n",
    "    \n",
    "    # Plot some classes to verify that the labels are intact\n",
    "    if plot_flag: \n",
    "        \n",
    "        zzz = np.where(np.array(y_train_num) == 2)\n",
    "        Class_train_2 = []\n",
    "        for k in range(len(zzz[0])):\n",
    "            p = X_train_im[zzz[0][k]]\n",
    "            Class_train_2.append(p)\n",
    "\n",
    "        zzz = np.where(np.array(y_test_num) == 3)\n",
    "        Class_test_3 = []\n",
    "        for k in range(len(zzz[0])):\n",
    "            p = X_test_im[zzz[0][k]]\n",
    "            Class_test_3.append(p)\n",
    "\n",
    "        plt.figure()\n",
    "        print(ll[2])\n",
    "        random_image_montage(Class_train_2)\n",
    "\n",
    "        plt.figure()\n",
    "        print(ll[3])\n",
    "        random_image_montage(Class_test_3)\n",
    "\n",
    "    # Classification --------------------------------\n",
    "        \n",
    "    cla = [] # accumlate the classifiers\n",
    "    cla.append(LinearDiscriminantAnalysis())\n",
    "    cla.append(KNeighborsClassifier())\n",
    "    cla.append(DecisionTreeClassifier())\n",
    "    cla.append(SVC(gamma=0.1, kernel=\"rbf\"))\n",
    "    cla.append(BaggingClassifier())\n",
    "    cla.append(RandomForestClassifier())\n",
    "    \n",
    "    DataNames = ['DataHOG', 'DataLBP', 'DataRGB', 'DataH10']\n",
    "    \n",
    "\n",
    "    accs = np.zeros((len(cl_names),len(DataNames)))\n",
    "    accs_tr = np.zeros((len(cl_names),len(DataNames)))\n",
    "    for i in range(len(cl_names)):\n",
    "        classifier = cla[i]\n",
    "        for j in range(len(DataNames)):\n",
    "            current_training_data = data_train[j]\n",
    "            current_testing_data = data_test[j]\n",
    "            classifier.fit(current_training_data,y_train_num)\n",
    "            assigned_labels = classifier.predict(current_testing_data)\n",
    "            accs[i,j] = np.mean(y_test_num == assigned_labels)\n",
    "            assigned_labels = classifier.predict(current_training_data)\n",
    "            accs_tr[i,j] = np.mean(y_train_num == assigned_labels)\n",
    "\n",
    "    print('Training\\n',accs_tr)\n",
    "    print('\\nTesting\\n',accs)\n",
    "\n",
    "    # Save results\n",
    "    np.savetxt(\"ClassifierAccSimpleFeatures_\"+ \\\n",
    "        video+\".csv\", accs, delimiter=\",\")   \n",
    "    \n",
    "    DataHOG = np.vstack((data_train[0],data_test[0]))\n",
    "    DataLBP = np.vstack((data_train[1],data_test[1]))\n",
    "    DataRGB = np.vstack((data_train[2],data_test[2]))\n",
    "    DataH10 = np.vstack((data_train[3],data_test[3]))\n",
    "    Labels = np.vstack((np.reshape(y_train_num,(-1,1)), \\\n",
    "                        np.reshape(y_test_num,(-1,1))))\n",
    "    \n",
    "    \n",
    "    np.savetxt(video+\"_DataHOG.csv\", DataHOG, delimiter=\",\")\n",
    "    np.savetxt(video+\"_DataLBP.csv\", DataLBP, delimiter=\",\")\n",
    "    np.savetxt(video+\"_DataRGB.csv\", DataRGB, delimiter=\",\")\n",
    "    np.savetxt(video+\"_DataH10.csv\", DataH10, delimiter=\",\")\n",
    "    np.savetxt(video+\"_Labels.csv\", Labels, delimiter=\",\")\n",
    "\n",
    "print(Sizes)\n",
    "np.savetxt('TrainingTestingSizes.csv', Sizes, delimiter=\",\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
